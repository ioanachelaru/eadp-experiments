======================================================================
CLUSTERING ANALYSIS FINDINGS SUMMARY
======================================================================
Analysis: Multi-K Clustering with Outlier Removal (Z > 3.0)
Date: Generated by clustering_analysis.py

======================================================================
ANT PROJECT FINDINGS
======================================================================

Recommended Configuration: k=3 (best V-Measure: 0.0572)

Cluster Risk Assessment:
  - Cluster 2 (18 samples): 55.6% defect rate - HIGH RISK
    These 18 classes share characteristics that make them ~10x more
    likely to be defective than the dataset average (5.7%).

  - Cluster 0 (1975 samples): 5.3% defect rate - TYPICAL
    The bulk of the codebase with average defect likelihood.

  - Cluster 1 (15 samples): 0% defect rate - LOW RISK
    Small cluster of outlier-like files with no defects.

Key Differentiating Metrics (by centroid separation):
  1. PMD_ctcnse (clone-related)
  2. PMD_rule_type_clone implementation rules
  3. PMD_clmmic (clone-related)
  4. PMD_rule_type_type resolution rules

Interpretation:
  Clone-related PMD metrics are the strongest differentiators between
  clusters in the Ant project. High-risk code tends to have more
  clone implementation issues.

======================================================================
CALCITE PROJECT FINDINGS
======================================================================

Recommended Configuration: k=5 (best V-Measure: 0.0057)

Note: V-Measure is low overall, indicating clustering structure does
not align strongly with defect labels. This suggests defects in Calcite
may be driven by factors not well captured by these metrics, or defects
are more uniformly distributed across code characteristics.

Cluster Risk Assessment:
  - Cluster 0 (79 samples): 22.8% defect rate - HIGH RISK
    These classes are ~3x more likely to be defective than average (7.6%).

  - Cluster 1 (18,891 samples): 7.5% defect rate - TYPICAL
    The vast majority of the codebase with average defect likelihood.

  - Clusters 2-4 (48, 26, 47 samples): 0% defect rate - LOW RISK
    Small clusters of outlier-like files with no defects.

Key Differentiating Metrics (by centroid separation):
  1. PMD_pci (problematic code indicator)
  2. PMD_rule_type_clone implementation rules
  3. PMD_ctcnse (clone-related)
  4. PMD_apmp

Interpretation:
  Similar to Ant, clone-related metrics and general code quality
  indicators (PMD violations) are key differentiators. The high-risk
  cluster (79 files) warrants focused attention during code reviews
  and testing.

======================================================================
PRACTICAL RECOMMENDATIONS
======================================================================

1. PRIORITIZE TESTING
   Focus testing efforts on files in high-risk clusters:
   - Ant: 18 files in Cluster 2 (55.6% defect rate)
   - Calcite: 79 files in Cluster 0 (22.8% defect rate)

2. CODE REVIEW FOCUS
   Examine the top features (see feature_relevance in JSON results)
   to understand what metric values characterize risky code. Set
   review thresholds based on these metrics.

3. TECHNICAL DEBT INDICATORS
   Clone-related metrics (PMD_ctcnse, PMD_clmmic, clone implementation
   rules) are strong predictors of defects in both projects. Consider
   refactoring to reduce code duplication.

4. METRIC THRESHOLDS
   Use the cluster centroids to establish threshold values for
   metrics that distinguish high-risk from low-risk code.

======================================================================
LIMITATIONS
======================================================================

- External metrics (V-Measure) are relatively low, indicating
  clustering structure does not perfectly align with defect labels.

- Small high-risk clusters may represent specific code patterns
  rather than generalizable defect predictors.

- Outlier removal (Z > 3.0) excludes extreme cases that may also
  be informative.

- K-Means assumes spherical clusters; other algorithms (DBSCAN,
  hierarchical) might reveal different patterns.

======================================================================
FILES REFERENCE
======================================================================

Detailed results are available in:
  - ant_results.json / calcite_results.json (per-k subdirectories)
  - k_comparison_chart.png (visual comparison across k values)
  - multi_k_comparison.txt (full numerical report)
  - visualizations/*.png (PCA cluster plots)

======================================================================
