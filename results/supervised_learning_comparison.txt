================================================================================
COMPREHENSIVE SUPERVISED LEARNING COMPARISON
SM vs Effort Features for Defect Prediction
================================================================================
Generated: 2026-01-24 21:22:23

--------------------------------------------------------------------------------
DATASETS
--------------------------------------------------------------------------------

calcite-top30-sm-only-v1.1+:
  Description: Calcite: top-30 SM features (v1.1.0+ only, for fair comparison)
  Samples: 18676
  Features: 30
  Defective: 1399 (7.49%)

calcite-effort-cov-only:
  Description: Calcite: 26 effort + 5 coverage features (31 total)
  Samples: 18676
  Features: 31
  Defective: 1399 (7.49%)

calcite-top30-sm-cov-effort:
  Description: Calcite: top-30 SM + 5 coverage + 26 effort (61 features)
  Samples: 18676
  Features: 61
  Defective: 1399 (7.49%)

--------------------------------------------------------------------------------
RANDOM FOREST RESULTS (5-fold stratified CV)
--------------------------------------------------------------------------------

Metric          |       SM-only (30)       |     Effort+Cov (31)      |      Combined (61)      
-----------------------------------------------------------------------------------------------
Precision       | 0.3916 +/- 0.0245        | 0.8077 +/- 0.0254        | 0.8169 +/- 0.0317   |
Recall          | 0.3202 +/- 0.0213        | 0.5154 +/- 0.0214        | 0.5190 +/- 0.0265   |
F1-Score        | 0.3515 +/- 0.0158        | 0.6290 +/- 0.0207        | 0.6345 +/- 0.0270   |
ROC-AUC         | 0.6623 +/- 0.0120        | 0.9470 +/- 0.0069        | 0.9490 +/- 0.0107   |
PR-AUC          | 0.1763 +/- 0.0103        | 0.4528 +/- 0.0244        | 0.4605 +/- 0.0324   |

--------------------------------------------------------------------------------
LOGISTIC REGRESSION RESULTS (5-fold stratified CV)
--------------------------------------------------------------------------------

Metric          |       SM-only (30)       |     Effort+Cov (31)      |      Combined (61)      
-----------------------------------------------------------------------------------------------
Precision       | 0.1381 +/- 0.0174        | 0.1880 +/- 0.0058        | 0.1943 +/- 0.0058   |
Recall          | 0.1515 +/- 0.0195        | 0.7169 +/- 0.0178        | 0.7391 +/- 0.0245   |
F1-Score        | 0.1439 +/- 0.0163        | 0.2978 +/- 0.0065        | 0.3076 +/- 0.0064   |
ROC-AUC         | 0.6003 +/- 0.0086        | 0.8224 +/- 0.0072        | 0.8270 +/- 0.0076   |
PR-AUC          | 0.0847 +/- 0.0035        | 0.1559 +/- 0.0035        | 0.1631 +/- 0.0038   |

--------------------------------------------------------------------------------
KEY FINDINGS
--------------------------------------------------------------------------------

1. EFFORT + COVERAGE FEATURES DRAMATICALLY OUTPERFORM SM-ONLY:

   Random Forest F1-Score:
   - SM-only:      35.2%
   - Effort+Cov:   62.9% (+79% improvement)
   - Combined:     63.4% (+80% improvement)

   Random Forest ROC-AUC:
   - SM-only:      0.6623
   - Effort+Cov:   0.9470 (+28.5 points)
   - Combined:     0.9490 (+28.7 points)

2. RANDOM FOREST OUTPERFORMS LOGISTIC REGRESSION:

   RF handles non-linear relationships and feature interactions better.
   - RF Combined F1: 63.4%
   - LR Combined F1: 30.8%

3. COMBINED FEATURES PROVIDE MARGINAL IMPROVEMENT OVER EFFORT+COV ALONE:

   Adding 30 SM features to Effort+Coverage:
   - F1:     62.9% -> 63.4% (+0.5 points)
   - AUC:    0.9470 -> 0.9490 (+0.2 points)

   Suggests Effort+Coverage captures most predictive information.

--------------------------------------------------------------------------------
TOP 10 FEATURES BY RANDOM FOREST IMPORTANCE
--------------------------------------------------------------------------------

calcite-top30-sm-only-v1.1+:
   1. SM_method_cco_avg: 0.7837
   2. SM_interface_cboi_stdev: 0.0508
   3. SM_interface_nod_stdev: 0.0241
   4. SM_interface_noc_stdev: 0.0197
   5. SM_method_cco_median: 0.0195
   6. SM_method_ci_median: 0.0161
   7. SM_enum_cloc_stdev: 0.0116
   8. SM_enum_dloc_stdev: 0.0104
   9. SM_enum_tcloc_stdev: 0.0097
  10. SM_enum_cboi_stdev: 0.0071

calcite-effort-cov-only:
   1. COV_BRANCH: 0.1338
   2. COV_INSTRUCTION: 0.0849
   3. COV_COMPLEXITY: 0.0764
   4. COV_LINE: 0.0732
   5. COV_METHOD: 0.0580
   6. HASSAN_whcm: 0.0527
   7. MOSER_weighted_age: 0.0438
   8. PMD_severity_minor: 0.0374
   9. PMD_severity_major: 0.0363
  10. MOSER_sum_lines_deleted: 0.0355

calcite-top30-sm-cov-effort:
   1. COV_BRANCH: 0.1173
   2. COV_INSTRUCTION: 0.0793
   3. COV_LINE: 0.0724
   4. COV_COMPLEXITY: 0.0690
   5. HASSAN_whcm: 0.0559
   6. COV_METHOD: 0.0558
   7. HASSAN_hcm: 0.0404
   8. MOSER_weighted_age: 0.0366
   9. PMD_severity_major: 0.0365
  10. PMD_severity_minor: 0.0361

--------------------------------------------------------------------------------
COMPARISON WITH CLUSTERING (DBSCAN)
--------------------------------------------------------------------------------

Clustering results for reference:
  - Recall:    ~5-8%
  - Precision: ~25-47%
  - F1-Score:  ~8-14%

Supervised learning (Random Forest) improvement:
  SM-only:      Recall 32.0%, Precision 39.2%, F1 35.2%
  Effort+Cov:   Recall 51.5%, Precision 80.8%, F1 62.9%

  Effort+Coverage achieves ~9x better recall than clustering

================================================================================
CONCLUSION
================================================================================

1. Supervised learning dramatically outperforms clustering for defect prediction.
   The class_weight="balanced" parameter addresses the class imbalance.

2. EFFORT + COVERAGE features are far more predictive than Software Metrics (SM).
   Top predictors: test coverage (branch/instruction), code churn (HASSAN_whcm),
   file age (MOSER_weighted_age), and code quality warnings (PMD severity).

3. SM features add minimal value when Effort+Coverage are available.
   The combined model shows only marginal improvement over Effort+Cov alone.

4. Practical implication: For defect prediction, prioritize collecting test
   coverage and code churn data over complex software metric extraction.
